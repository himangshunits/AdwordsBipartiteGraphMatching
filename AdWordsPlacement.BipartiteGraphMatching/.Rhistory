nd <- ndiffs(varianceStablizedMcopper)
if(nd > 0)
finalMcopper <- diff(varianceStablizedMcopper, differences = nd)
plot(finalMcopper)
Acf(finalMcopper)
data("enplanements")
# First glance of the series
plot(enplanements)
Acf(enplanements)
plot(stl(enplanements, s.window = 12))
lambda = BoxCox.lambda(enplanements)
plot(BoxCox(enplanements, lambda))
plot(log(enplanements))
# Check again with STL
plot(stl(BoxCox(enplanements, lambda), s.window = 12))
plot(stl(log(enplanements), s.window = 12))
# Both boxCox and log seems to give similar results. So we will be using BoxCox()
varianceStablizedEnplanements <- BoxCox(enplanements, lambda)
# Try applying diff to remove trend.
nd <- ndiffs(varianceStablizedEnplanements)
if(nd > 0)
finalEnplanements <- diff(varianceStablizedEnplanements, differences = nd)
# Check if it becomes Staionary now.
plot(finalEnplanements)
Acf(finalEnplanements)
# ACF plot shows perfectly balanced data between critical values, so the data is staionary.
#
data("visitors")
# First glance of the series
plot(visitors)
Acf(visitors)
plot(stl(visitors, s.window = 12))
#
lambda = BoxCox.lambda(visitors)
plot(BoxCox(visitors, lambda))
plot(log(visitors))
# Check again with STL
plot(stl(BoxCox(visitors, lambda), s.window = 12))
plot(stl(log(visitors), s.window = 12))
# Both boxCox and log seems to give similar results. So we will be using BoxCox()
varianceStablizedVisitors <- BoxCox(visitors, lambda)
# Try applying diff to remove trend.
nd <- ndiffs(varianceStablizedVisitors)
if(nd > 0)
finalVisitors <- diff(varianceStablizedVisitors, differences = nd)
# Check if it becomes Staionary now.
plot(finalVisitors)
Acf(finalVisitors)
# ACF plot shows perfectly balanced data between critical values, so the data is staionary.
#
?holt
require(fpp)
data(books)
plot(books, main = "Data set books")
# Apply holt's linear model to hardcover Series
fcastPaperHard = holt(books[,"Hardcover"],
initial = "optimal",
h = 4)
# Plot the model.
plot(fcastPaperHard)
# Apply holt's linear model to paperback Series
fcastPaperPaper = holt(books[,"Paperback"],
initial = "optimal",
h = 4)
# plot the series.
plot(fcastPaperPaper)
SSE_HOLT_HARD <- sum((books[,"Hardcover"] - fcastPaperHard$fitted)^2)
require(fpp)
data(books)
plot(books, main = "Data set books")
alpha = seq(0.01, 0.99, 0.01)
SSE = NA
for(i in seq_along(alpha)) {
fcast = ses(books[,"Hardcover"], alpha = alpha[i], initial = "simple")
SSE[i] = sum((books[,"Hardcover"] - fcast$fitted)^2)
}
plot(alpha, SSE, type = "l")
SSE_HOLT_PAPER <- sum((books[,"Paperback"] - fcastPaperPaper$fitted)^2)
# Make SES models
fcastSesHard <- ses(books[,"Hardcover"],
initial = "optimal",
h = 4)
fcastSesPaper <- ses(books[,"Paperback"],
initial = "optimal",
h = 4)
# Compute SSE For SES, HARDCOVER
SSE_SES_HARD <- sum((books[,"Hardcover"] - fcastSesHard$fitted)^2)
# Compute SSE For SES, PAPERBACK
SSE_SES_PAPER <- sum((books[,"Paperback"] - fcastSesPaper$fitted)^2)
SSE_HOLT_HARD
SSE_HOLT_PAPER
SSE_SES_HARD
SSE_SES_PAPER
accuracy(fcastPaperHard)
plot(fcastSesHard)
plot(fcastPaperHard)
plot(fcastPaperPaper)
plot(fcastSesPaper)
Acf(fcast)
fcast
Acf(fcastPaperHard$residuals)
Acf(fcastPaperPaper$residuals)
Acf(fcastSesPaper$residuals)
Acf(fcastSesHard$residuals)
accuracy(fcastSesPaper)
accuracy(fcastPaperPaper)
accuracy(fcastSesHard)
accuracy(fcastPaperHard)
?accuracy
require(multcomp)
install.packages("multcomp")
require(multcomp)
attach(cholesterol)
head(cholesterol)
table(trt)
?attach
aggregate(cholesterol$response, by = list(cholesterol$trt), FUN = mean())
aggregate(cholesterol$response, by = list(cholesterol$trt), FUN = mean)
data("HouseVotes84")
library(mlbench)
install.packages("cvTools")
install.packages("mlbench")
install.packages("cvTools")
install.packages("e1071")
library(mlbench)
library(cvTools)
library(e1071)
data("HouseVotes84")
data<-HouseVotes84
#cross fold
folds<-cvFolds(nrow(data),10,type="random")
MSE=0
for( i in 1:10)
{
ind<-which(folds$which==i)
testSet<-data[ind,]
trainingSet<-data[-ind,]
m<-naiveBayes(V5~V1+V2+V3+V4,data=trainingSet)
print(m)
#m<-glm(V5~V1+V2+V3+V4,data=trainingSet,family=binomial(link = "logit"))
ans <- predict(m, testSet[,1:4])
print(ans)
t <- table(ans,testSet[,5])
MSE[i] = (sum(t) - sum(diag(t)))/sum(t)
}
print(MSE)
hist(MSE)
qqnorm(MSE)
t.test(MSE, alternative = "greater", mu = 0.1087333)
print(MSE)
hist(MSE)
t.test(MSE, alternative = "greater", mu = 0.1087333)
t.test(MSE, alternative = "greater", mu = 0.15)
t.test(MSE, alternative = "greater", mu = 0.10000)
randT <- rt(3000, df=NROW(tips)-1)
require (ggplot2)
ggplot(data.frame(x=randT)) +
geom_density(aes(x=x), fill="grey", color="grey") +
geom_vline(xintercept=tipTTest$statistic, color="red") +
geom_vline(xintercept=mean(randT) +
c(-2,2)*sd(randT), linetype=2)
randT <- rt(3000, df=NROW(tips)-1)
data(tips, package = "reshape2")
randT <- rt(3000, df=NROW(tips)-1)
require (ggplot2)
ggplot(data.frame(x=randT)) +
geom_density(aes(x=x), fill="grey", color="grey") +
geom_vline(xintercept=tipTTest$statistic, color="red") +
geom_vline(xintercept=mean(randT) +
c(-2,2)*sd(randT), linetype=2)
randT <- rt(3000, df=NROW(tips)-1)
tipTTest <- t.test(tips$tip,
alternative="two.sided",
mu=2.5)
require (ggplot2)
ggplot(data.frame(x=randT)) +
geom_density(aes(x=x), fill="grey", color="grey") +
geom_vline(xintercept=tipTTest$statistic, color="red") +
geom_vline(xintercept=mean(randT) +
c(-2,2)*sd(randT), linetype=2)
testRes <- t.test(MSE, alternative = "greater", mu = 0.15)
require (ggplot2)
ggplot(data.frame(x=MSE)) +
geom_density(aes(x=x), fill="grey", color="grey") +
geom_vline(xintercept=testRes$statistic, color="red") +
geom_vline(xintercept=mean(MSE) +
c(-2,2)*sd(MSE), linetype=2)
randT <- rt(3000, df=NROW(tips)-1)
tipTTest <- t.test(tips$tip,
alternative="two.sided",
mu=2.5)
require (ggplot2)
ggplot(data.frame(x=randT)) +
geom_density(aes(x=x), fill="grey", color="grey") +
geom_vline(xintercept=tipTTest$statistic, color="red") +
geom_vline(xintercept=mean(randT) +
c(-2,2)*sd(randT), linetype=2)
require (ggplot2)
ggplot(data.frame(x=MSE)) +
geom_density(aes(x=x), fill="grey", color="grey") +
geom_vline(xintercept=testRes$statistic, color="red") +
geom_vline(xintercept=mean(MSE) +
c(-2,2)*sd(MSE), linetype=2)
t.test(tips$tip,
alternative="two.sided",
mu=2.5)
t.test(tips$tip, alternative="greater", mu=2.5)
t.test(tips$tip, alternative="greater", mu=4)
library(mlbench)
library(cvTools)
library(e1071)
data("HouseVotes84")
data<-HouseVotes84
#cross fold
folds<-cvFolds(nrow(data),10,type="random")
MSE=0
for( i in 1:10)
{
ind<-which(folds$which==i)
testSet<-data[ind,]
trainingSet<-data[-ind,]
m<-naiveBayes(V5~V1+V2+V3+V4,data=trainingSet)
print(m)
ans <- predict(m, testSet[,1:4])
print(ans)
t <- table(ans,testSet[,5])
MSE[i] = (sum(t) - sum(diag(t)))/sum(t)
}
# Error Series
print(MSE)
# Check for Normality
qqnorm(MSE)
testRes <- t.test(MSE, alternative = "greater", mu = 0.15)
testRes
require (ggplot2)
ggplot(data.frame(x=MSE)) +
geom_density(aes(x=x), fill="grey", color="grey") +
geom_vline(xintercept=testRes$statistic, color="red") +
geom_vline(xintercept=mean(MSE) +
c(-2,2)*sd(MSE), linetype=2)
head(HouseVotes84)
nrow(HouseVotes84)
ncol(HouseVotes84)
ls()
library(fpp)
hsales
acf(books)
acf(books[,"hardcover"])
books[,"hardcover"]
books
books[,"Hardcover"]
data(package ="fma")
data("hsales")
plot(hslaes)
data("hsales")
plot(hsales)
plot(dj)
plot(books[,"Paperback"])
?ets
ets(books[,"Paperback"])
ets(books[,"Hardcover"])
plot(books[,"Hardcover"])
ets(books[,"Hardcover"])
require(fpp)
data(books)
plot(books, main = "Data set books")
#============================================================#
# Answer to A
#============================================================#
# Apply holt's linear model to hardcover Series
fcastPaperHard <- holt(books[,"Hardcover"],
initial = "optimal",
h = 4)
# Plot the model.
plot(fcastPaperHard)
# Apply holt's linear model to paperback Series
fcastPaperPaper <- holt(books[,"Paperback"],
initial = "optimal",
h = 4)
# plot the series.
plot(fcastPaperPaper)
#============================================================#
# Answer to B
#============================================================#
#
# Compute SSE For HOLT, HARDCOVER
SSE_HOLT_HARD <- sum((books[,"Hardcover"] - fcastPaperHard$fitted)^2)
# Compute SSE For HOLT, PAPERBACK
SSE_HOLT_PAPER <- sum((books[,"Paperback"] - fcastPaperPaper$fitted)^2)
# Make SES models
fcastSesHard <- ses(books[,"Hardcover"],
initial = "optimal",
h = 4)
fcastSesPaper <- ses(books[,"Paperback"],
initial = "optimal",
h = 4)
# Compute SSE For SES, HARDCOVER
SSE_SES_HARD <- sum((books[,"Hardcover"] - fcastSesHard$fitted)^2)
# Compute SSE For SES, PAPERBACK
SSE_SES_PAPER <- sum((books[,"Paperback"] - fcastSesPaper$fitted)^2)
#============================================================#
# Answer to C
#============================================================#
# Find the Accuracy of all the 4 models.
accuracy(fcastSesPaper)
accuracy(fcastPaperPaper)
accuracy(fcastSesPaper)
accuracy(fcastPaperPaper)
accuracy(fcastSesHard)
accuracy(fcastPaperHard)
accuracy(fcastSesPaper)
accuracy(fcastPaperPaper)
accuracy(fcastSesHard)
accuracy(fcastPaperHard)
require(fpp)
data(ukcars)
plot(ukcars, ylab = "Production, thousands of cars")
stlFit <- stl(ukcars, s.window = "periodic")
plot(stlFit)
adjusted <- seasadj(stlFit)
plot(adjusted)
fcastHoltDamp = holt(adjusted, damped=TRUE, h = 8)
plot(ukcars, xlim = c(1977, 2008))
lines(fcastHoltDamp$mean +
stlFit$time.series[2:9,"seasonal"],
col = "red", lwd = 2)
dampHoltRMSE = sqrt(mean(((fcastHoltDamp$fitted + stlFit$time.series[,"seasonal"]) - ukcars)^2))
dampHoltRMSE
fcastHolt = holt(adjusted, h = 8)
plot(ukcars, xlim = c(1997, 2008))
lines(fcastHolt$mean + stlFit$time.series[2:9,"seasonal"],
col = "red", lwd = 2)
holtRMSE = sqrt(mean(((fcastHolt$fitted + stlFit$time.series[,"seasonal"]) - ukcars)^2))
holtRMSE
?ets
require(fpp)
data(ukcars)
ets(ukcars)
temp <- ets(ukcars)
accuracy(temp)
fcastEts <- ets(ukcars)
etsRMSE = sqrt(mean(((fcastEts$fitted) - ukcars)^2))
etsRMSE
# Models built by Sam
require(fpp)
data(ukcars)
plot(ukcars, ylab = "Production, thousands of cars")
stlFit <- stl(ukcars, s.window = "periodic")
plot(stlFit)
adjusted <- seasadj(stlFit)
plot(adjusted)
fcastHoltDamp = holt(adjusted, damped=TRUE, h = 8)
plot(ukcars, xlim = c(1977, 2008))
lines(fcastHoltDamp$mean +
stlFit$time.series[2:9,"seasonal"],
col = "red", lwd = 2)
dampHoltRMSE = sqrt(mean(((fcastHoltDamp$fitted + stlFit$time.series[,"seasonal"]) - ukcars)^2))
dampHoltRMSE
fcastHolt = holt(adjusted, h = 8)
plot(ukcars, xlim = c(1997, 2008))
lines(fcastHolt$mean + stlFit$time.series[2:9,"seasonal"],
col = "red", lwd = 2)
holtRMSE = sqrt(mean(((fcastHolt$fitted + stlFit$time.series[,"seasonal"]) - ukcars)^2))
holtRMSE
fcastEts
plot(fcastEts)
plot(ukcars, xlim = c(1997, 2008))
lines(fcastHolt$mean + stlFit$time.series[2:9,"seasonal"],
col = "red", lwd = 2)
plot(fcastHolt)
lines(fcastEts$mean,
col = "red", lwd = 2)
plot(uk)
plot(ukcars)
lines(fcastEts$mean,
col = "red", lwd = 2)
fcastEts$fitted
?ets
plot(fcastEts$fitted)
?forecast
fcastEtsData <- ets(ukcars)
fcastEts <- forecast(fcastEtsData, h = 8)# damped = TRUE needed?
etsRMSE = sqrt(mean(((fcastEts$fitted) - ukcars)^2))
etsRMSE
accuracy(fcastEts)
plot(fcastEts)
dampHoltRMSE
holtRMSE
plot(ukcars, xlim = c(1997, 2008))
lines(fcastEts$mean,
col = "red", lwd = 2)
plot(ukcars, xlim = c(1997, 2008))
lines(fcastHolt$mean + stlFit$time.series[2:9,"seasonal"],
col = "red", lwd = 2)
fcastEtsData
?ets
dampHoltRMSE
holtRMSE
etsRMSE
plot(elecequip)
require(fpp)
data("elecequip")
# 1. Plot and examine for any unusual patterns in the electrical equipment orders time series data (elecequip).
plot(elecequip)
plot(elecequip)
acf(elecequip)
decomposedData <- stl(elecequip, s.window = "periodic")
plot(decomposedData)
decomposedData$time.series
?seasadj
seasAdjData <- seasadj(decomposedData)
plot(seasAdjData)
plot(stl(seasAdjData, s.window = "periodic"))
plot(seasAdjData)
lines(elecequip)
lines(elecequip, col="grey")
seasAdjData <- seasadj(decomposedData)
lines(elecequip, col="grey")
plot(seasAdjData, col = "red")
plot(elecequip, col="grey")
lines(seasAdjData, col = "red")
acf(seasAdjData)
plot(stl(seasAdjData, s.window = "periodic"))
acf(seasAdjData)
lambda = BoxCox.lambda(seasAdjData)
boxCoxData <- BoxCox(seasAdjData, lambda)
plot(boxCoxData)
plot(stl(boxCoxData, s.window = "periodic"))
acf(boxCoxData)
acf(seasAdjData)
acf(diff(boxCoxData))
plot(stl(seasAdjData, s.window = "periodic"))
acf(seasAdjData)
nsdiffs(seasAdjData)
ndiffs(seasAdjData)
nd <- ndiffs(seasAdjData)
if(nd > 0)
diffData <- diff(seasAdjData, differences = nd)
plot(diffData)
plot(stl(diffData, s.window = "periodic"))
acf(diffData)
auto.arima(diffData)
plot(auto.arima(diffData))
plot(forecast(auto.arima(diffData)))
arimaFit <- auto.arima(diffData)
summary(arimaFit)
arima400 <- Arima(diffData, order=c(4,0,0))
plot(arima400)
arima400
?auto.arima
?AIC
summary(arimaFit)
summary
summary(arima400)
summary(arima400)
arima400 <- Arima(diffData, order=c(2,0,0))
summary(arimaFit)
arima400 <- Arima(diffData, order=c(4,0,0))
summary(arima400)
arima300 <- Arima(diffData, order=c(3,0,0))
summary(arima300)
arima200 <- Arima(diffData, order=c(2,0,0))
summary(arima200)
arimaFit$residuals
residuals(arimaFit)
plot(residuals(arimaFit))
plot(arimaFit$residuals)
plot(forecast(arimaFit)$residuals)
acf(arimaFit$residuals)
res <- arimaFit$residuals # same as residuals(arimaFit)
plot(res)
acf(res)
Box.test(dj, lag=10, fitdf=0)
Box.test(dj, lag=10, fitdf=0, type="Lj")
Box.test(dj, lag=8, fitdf=0, type="Lj")
Box.test(dj, lag=80, fitdf=0, type="Lj")
Box.test(dj, lag=12, fitdf=0, type="Lj")
x <- rnorm (100)
Box.test (x, lag = 1)
Box.test (x, lag = 1, type = "Ljung")
summary(arimaFit)
Box.test(dj, lag=10, fitdf=4)
Box.test(dj, lag=10, fitdf=4, type="Lj")
Box.test(res, lag=24, fitdf=4)
Box.test(res, lag=10, fitdf=4, type="Lj")
# Very small p-value of Box tests suggest that the null hypothesis (That the res is a white noise) will be rejected. So the data is not a white noise.
res <- arimaFit$residuals # same as residuals(arimaFit)
plot(res)
acf(res)
Box.test(res, lag=24, fitdf=4)
Box.test(res, lag=10, fitdf=4, type="Lj")
Box.test(res, lag=24, fitdf=4, type="Lj")
Box.test(res, lag=10, fitdf=4)
arimaFit
plot(forecast(arimaFit))
?Box.test
setwd("/Users/Himangshu/Google Drive/NC_State_Spring_2016/Samatova!/Projects/BipartiteGraphMatching/07.Topic-7.Project-7.AdWordsPlacement.BipartiteGraphMatching/ ")
setwd("/Users/Himangshu/Google Drive/NC_State_Spring_2016/Samatova!/Projects/BipartiteGraphMatching/07.Topic-7.Project-7.AdWordsPlacement.BipartiteGraphMatching/")
MyData <- read.csv(file="bidder_dataset.csv", header=TRUE, sep=",")
View(MyData)
View(MyData)
unique(MyData[,"Keyword"])
length(unique(MyData[,"Keyword"]))
MyData[,"Keywords"]
MyData[,"Keyword"]
MyData[,"Advertiser"]
unique(MyData[,"Advertiser"])
length(unique(MyData[,"Advertiser"]))
length(unique(MyData[,"Keyword"]))
nrow(MyData)
unique(MyData[,"Keyword"])
MyData[1]["ihsa football scores"]
